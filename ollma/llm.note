User Input: "What is Python?"
    ↓
┌──────────────────────────────────────┐
│ Tokenization                         │
│ → [2054, 374, 13207, 30]             │
└──────────────────────────────────────┘
    ↓
╔══════════════════════════════════════╗
║   Autoregressive Loop (Repeats)      ║
╠══════════════════════════════════════╣
║ ┌──────────────────────────────────┐ ║
║ │ Token Embeddings                 │ ║
║ │ [seq_len, 4096]                  │ ║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │ + Position Embeddings            │ ║
║ │ [seq_len, 4096]                  │ ║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │ Transformer Block 1              │ ║
║ │ ┌────────────────────────────┐   │ ║
║ │ │ Layer Norm                 │   │ ║
║ │ │ Multi-Head Attention       │   │ ║
║ │ │ Residual Connection        │   │ ║
║ │ ├────────────────────────────┤   │ ║
║ │ │ Layer Norm                 │   │ ║
║ │ │ Feed-Forward Network       │   │ ║
║ │ │ Residual Connection        │   │ ║
║ │ └────────────────────────────┘   │ ║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │ Transformer Block 2              │ ║
║ │ (Same structure)                 │ ║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║    ... (Repeats 32 times)            ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │ Final Layer Normalization        │ ║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │好 (Output Projection)      │ ║
║ │ [seq_len, 4096] → [seq_len, 128256]║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │ Take logits[-1]                  │ ║
║ │ [128256]                         │ ║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │ Temperature + Softmax            │ ║
║ │ → Probability distribution [128256]║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │ Sampling                         │ ║
║ │ → next_token                     │ ║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │ tokens.append(next_token) ← Key! │ ║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ ┌──────────────────────────────────┐ ║
║ │ Check stopping condition         │ ║
║ │ if EOS or max_length: break      │ ║
║ └──────────────────────────────────┘ ║
║    ↓                                 ║
║ If not stopped, loop back to top ↻   ║
╚══════════════════════════════════════╝
    ↓
Final Output: "What is Python? Python is a high-level programming language..."